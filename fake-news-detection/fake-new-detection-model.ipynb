{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection Model\n",
    "\n",
    "\n",
    "People check out this paper: https://sites.cs.ucsb.edu/~william/papers/acl2017.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Column 1: the ID of the statement ([ID].json).\n",
    "    Column 2: the label.\n",
    "    Column 3: the statement.\n",
    "    Column 4: the subject(s).\n",
    "    Column 5: the speaker.\n",
    "    Column 6: the speaker's job title.\n",
    "    Column 7: the state info.\n",
    "    Column 8: the party affiliation.\n",
    "    Column 9-13: the total credit history count, including the current statement.\n",
    "    9: barely true counts.\n",
    "    10: false counts.\n",
    "    11: half true counts.\n",
    "    12: mostly true counts.\n",
    "    13: pants on fire counts.\n",
    "    Column 14: the context (venue / location of the speech or statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps Involved:**\n",
    "\n",
    "- **Preprocessing**\n",
    "    - Cleaning\n",
    "    - Steamming\n",
    "    - Contraction removal\n",
    "    - Special character removal\n",
    "- **EDA (Easiest Data Augmentation)** \n",
    "    - Word2Vec embedding enrichment\n",
    "    - Misspelling removal\n",
    "    - Feature creation\n",
    "\n",
    "- **Text Representation**\n",
    "    - Tokenization\n",
    "    - Text to sequence\n",
    "    - Padding sequence\n",
    "\n",
    "- **Modelling** \n",
    "    -  Convention models\n",
    "    - CNN, Bi-LSTM\n",
    "    \n",
    "- **Deployment** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_`Text Representation`_**\n",
    "\n",
    "    - Bags of Words\n",
    "    - TFIDF (Term Frequency Inverse Document Frequency)\n",
    "    - Hashing Vectorization\n",
    "    - Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to approach the problem on modelling front.\n",
    "\n",
    "- **Convention Methods (Convention Machine Learning approach)**\n",
    "    - Logistic Regression\n",
    "    - Support Vector Machine\n",
    "    - Navie Bayes Classifier\n",
    "        \n",
    "- **Deep Learning Methods**\n",
    "    - CNN\n",
    "    - Bi-LSTM\n",
    "    - Combination of above two ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing needes\n",
    "# Bag of words \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# TFIDF \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Hashing \n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Word2Vec\n",
    "# Python program to generate word vectors using Word2Vec \n",
    "# importing all necessary modules \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# !python3 -m pip install wordcloud\n",
    "#from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Peformance \n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,precision_recall_curve,f1_score,confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model_metrics(y_pred,y_test):\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('F1 score:', f1_score(y_test, y_pred,average='weighted'))\n",
    "    print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "    print('Precision:', precision_score(y_test, y_pred,average='weighted'))\n",
    "    print('\\n clasification report:\\n', classification_report(y_test, y_pred))\n",
    "    print('\\n confussion matrix:\\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id','class','statement','subjects','speaker','speaker_title','state','party_affiliation',\n",
    "           'barely_true_count','false_counts','half_true_counts','mostly_true_counts','pants_on_fire','context' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw=pd.read_csv('data/liar_dataset/train.tsv',delimiter='\\t',names=columns)\n",
    "validation_raw=pd.read_csv('data/liar_dataset/valid.tsv',delimiter='\\t',names=columns)\n",
    "test_raw=pd.read_csv('data/liar_dataset/test.tsv',delimiter='\\t',names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>statement</th>\n",
       "      <th>subjects</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_title</th>\n",
       "      <th>state</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true_count</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        class                                          statement  \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                             subjects         speaker         speaker_title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      state party_affiliation  barely_true_count  false_counts  \\\n",
       "0     Texas        republican                0.0           1.0   \n",
       "1  Virginia          democrat                0.0           0.0   \n",
       "2  Illinois          democrat               70.0          71.0   \n",
       "3       NaN              none                7.0          19.0   \n",
       "4   Florida          democrat               15.0           9.0   \n",
       "\n",
       "   half_true_counts  mostly_true_counts  pants_on_fire              context  \n",
       "0               0.0                 0.0            0.0             a mailer  \n",
       "1               1.0                 1.0            0.0      a floor speech.  \n",
       "2             160.0               163.0            9.0               Denver  \n",
       "3               3.0                 5.0           44.0       a news release  \n",
       "4              20.0                19.0            2.0  an interview on CNN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barely_true_count</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    barely_true_count  false_counts  half_true_counts  mostly_true_counts  \\\n",
       "12               34.0          32.0              58.0                33.0   \n",
       "\n",
       "    pants_on_fire  \n",
       "12           19.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw[train_raw['speaker']=='mitt-romney'].ix[:,'barely_true_count':'pants_on_fire'].head(1)\n",
    "# For example, Mitt Romney has a credit\n",
    "# history vector h = {19, 32, 34, 58, 33}, which corresponds to his counts of “pants on fire”, “false”,\n",
    "# “barely true”, “half true”, “mostly true” for historical statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "barack-obama                          488\n",
       "donald-trump                          273\n",
       "hillary-clinton                       239\n",
       "mitt-romney                           176\n",
       "scott-walker                          149\n",
       "                                     ... \n",
       "curt-schilling                          1\n",
       "jason-nassour                           1\n",
       "drug-policy-alliance                    1\n",
       "trusted-leadership-pac                  1\n",
       "national-association-manufacturers      1\n",
       "Name: speaker, Length: 2910, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['speaker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "half-true      2114\n",
       "false          1995\n",
       "mostly-true    1962\n",
       "true           1676\n",
       "barely-true    1654\n",
       "pants-fire      839\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Texas            1009\n",
       "Florida           997\n",
       "Wisconsin         713\n",
       "New York          657\n",
       "Illinois          556\n",
       "                 ... \n",
       "Tennesse            1\n",
       "Montana             1\n",
       "ohio                1\n",
       "Wisconsin           1\n",
       "Rhode Island        1\n",
       "Name: state, Length: 84, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "republican                      4497\n",
       "democrat                        3336\n",
       "none                            1744\n",
       "organization                     219\n",
       "independent                      147\n",
       "newsmaker                         56\n",
       "libertarian                       40\n",
       "activist                          39\n",
       "journalist                        38\n",
       "columnist                         35\n",
       "talk-show-host                    26\n",
       "state-official                    20\n",
       "labor-leader                      11\n",
       "tea-party-member                  10\n",
       "business-leader                    9\n",
       "green                              3\n",
       "education-official                 2\n",
       "Moderate                           1\n",
       "liberal-party-canada               1\n",
       "government-body                    1\n",
       "constitution-party                 1\n",
       "ocean-state-tea-party-action       1\n",
       "democratic-farmer-labor            1\n",
       "Name: party_affiliation, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['party_affiliation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=train_raw[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mostly-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class\n",
       "0        false\n",
       "1    half-true\n",
       "2  mostly-true\n",
       "3        false\n",
       "4    half-true"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = train_labels['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['false', 'half-true', 'mostly-true', 'true', 'barely-true',\n",
       "       'pants-fire'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>statement</th>\n",
       "      <th>subjects</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_title</th>\n",
       "      <th>state</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true_count</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      class                                          statement  \\\n",
       "0   2635.json      false  Says the Annies List political group supports ...   \n",
       "1  10540.json  half-true  When did the decline of coal start? It started...   \n",
       "\n",
       "                             subjects         speaker         speaker_title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "\n",
       "      state party_affiliation  barely_true_count  false_counts  \\\n",
       "0     Texas        republican                0.0           1.0   \n",
       "1  Virginia          democrat                0.0           0.0   \n",
       "\n",
       "   half_true_counts  mostly_true_counts  pants_on_fire          context  \n",
       "0               0.0                 0.0            0.0         a mailer  \n",
       "1               1.0                 1.0            0.0  a floor speech.  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remvoing ID from data because we are not able get text data correspding to ID json\n",
    "## Remvoving target class \n",
    "train.drop(['id','class'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>subjects</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_title</th>\n",
       "      <th>state</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true_count</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start? It started...   \n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                             subjects         speaker         speaker_title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      state party_affiliation  barely_true_count  false_counts  \\\n",
       "0     Texas        republican                0.0           1.0   \n",
       "1  Virginia          democrat                0.0           0.0   \n",
       "2  Illinois          democrat               70.0          71.0   \n",
       "3       NaN              none                7.0          19.0   \n",
       "4   Florida          democrat               15.0           9.0   \n",
       "\n",
       "   half_true_counts  mostly_true_counts  pants_on_fire              context  \n",
       "0               0.0                 0.0            0.0             a mailer  \n",
       "1               1.0                 1.0            0.0      a floor speech.  \n",
       "2             160.0               163.0            9.0               Denver  \n",
       "3               3.0                 5.0           44.0       a news release  \n",
       "4              20.0                19.0            2.0  an interview on CNN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding word2vec \n",
    "\n",
    "https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/\n",
    "\n",
    "https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-11-cnn-word2vec-41f5e28eda74\n",
    "\n",
    "\n",
    "Note: Only considering statement column as actual text which is available in ID filed is not accessible via API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_labels\n",
    "df2= test_raw[['statement']]\n",
    "df2_labels= test_raw[['class']]\n",
    "y_test = df2_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convetionl Methods to set up a base line\n",
    "\n",
    "### Text Representation\n",
    "\n",
    "- Bag of words (CountVectorizer)\n",
    "- TFIDF \n",
    "- Hashing\n",
    "- Word2Vec\n",
    "\n",
    "### Models to Try\n",
    "\n",
    "- Naive Bayes Classifer\n",
    "- Logistic Regression\n",
    "- Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= train\n",
    "test_df= df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words (CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vectorizer = CountVectorizer(dtype=np.float32,\n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3),min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vectorizer.fit(list(train_df.statement.values) + list(test_df.statement.values))\n",
    "xtrain_cntv =  cnt_vectorizer.transform(train_df.statement.values) \n",
    "xtest_cntv = cnt_vectorizer.transform(test_df.statement.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22869"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnt_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_cntv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10240, 22869)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_cntv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_cntv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= clf.predict(xtest_cntv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.244672454617206\n",
      "F1 score: 0.24170286932296786\n",
      "Recall: 0.244672454617206\n",
      "Precision: 0.2421979288134382\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.23      0.19      0.21       212\n",
      "       false       0.29      0.35      0.31       249\n",
      "   half-true       0.22      0.21      0.22       265\n",
      " mostly-true       0.23      0.24      0.23       241\n",
      "  pants-fire       0.24      0.14      0.18        92\n",
      "        true       0.25      0.27      0.26       208\n",
      "\n",
      "    accuracy                           0.24      1267\n",
      "   macro avg       0.24      0.23      0.23      1267\n",
      "weighted avg       0.24      0.24      0.24      1267\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[41 51 49 32 11 28]\n",
      " [37 86 36 43  9 38]\n",
      " [36 60 56 66  9 38]\n",
      " [32 37 52 58  7 55]\n",
      " [13 31 19  9 13  7]\n",
      " [23 35 39 49  6 56]]\n"
     ]
    }
   ],
   "source": [
    "display_model_metrics(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelNB = MultinomialNB(alpha=0.1)\n",
    "modelNB.fit(xtrain_cntv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelNB.predict(xtest_cntv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2541436464088398\n",
      "F1 score: 0.2546755622193559\n",
      "Recall: 0.2541436464088398\n",
      "Precision: 0.25654155347626184\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.23      0.22      0.23       212\n",
      "       false       0.29      0.27      0.28       249\n",
      "   half-true       0.26      0.24      0.25       265\n",
      " mostly-true       0.26      0.27      0.26       241\n",
      "  pants-fire       0.18      0.25      0.21        92\n",
      "        true       0.26      0.27      0.27       208\n",
      "\n",
      "    accuracy                           0.25      1267\n",
      "   macro avg       0.25      0.25      0.25      1267\n",
      "weighted avg       0.26      0.25      0.25      1267\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[47 42 41 26 31 25]\n",
      " [35 66 43 36 29 40]\n",
      " [42 42 64 65 15 37]\n",
      " [31 18 52 65 15 60]\n",
      " [22 21 12 12 23  2]\n",
      " [23 36 34 46 12 57]]\n"
     ]
    }
   ],
   "source": [
    "display_model_metrics(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "svc.fit(xtrain_cntv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(xtest_cntv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2280978689818469\n",
      "F1 score: 0.2272794496328766\n",
      "Recall: 0.2280978689818469\n",
      "Precision: 0.22728152796159046\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.21      0.21      0.21       212\n",
      "       false       0.28      0.30      0.29       249\n",
      "   half-true       0.22      0.18      0.20       265\n",
      " mostly-true       0.21      0.23      0.22       241\n",
      "  pants-fire       0.20      0.18      0.19        92\n",
      "        true       0.23      0.23      0.23       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.22      0.22      0.22      1267\n",
      "weighted avg       0.23      0.23      0.23      1267\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[45 46 34 39 17 31]\n",
      " [42 75 33 46 17 36]\n",
      " [39 57 49 65 15 40]\n",
      " [42 28 59 55  8 49]\n",
      " [18 23 17 10 17  7]\n",
      " [28 36 35 49 12 48]]\n"
     ]
    }
   ],
   "source": [
    "display_model_metrics(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note : Looks like Navie Bayes Classifer has performed better than SVM and LG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF (Term Frequency Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "tfv = TfidfVectorizer(dtype=np.float32, min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(train_df.statement.values) + list(test_df.statement.values))\n",
    "xtrain_tfv =  tfv.transform(train_df.statement.values) \n",
    "xvalid_tfv = tfv.transform(test_df.statement.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10546"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10240, 10546)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note : The number for features are reduce by half if we use TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_cntv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= clf.predict(xtest_cntv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.244672454617206\n",
      "F1 score: 0.24170286932296786\n",
      "Recall: 0.244672454617206\n",
      "Precision: 0.2421979288134382\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.23      0.19      0.21       212\n",
      "       false       0.29      0.35      0.31       249\n",
      "   half-true       0.22      0.21      0.22       265\n",
      " mostly-true       0.23      0.24      0.23       241\n",
      "  pants-fire       0.24      0.14      0.18        92\n",
      "        true       0.25      0.27      0.26       208\n",
      "\n",
      "    accuracy                           0.24      1267\n",
      "   macro avg       0.24      0.23      0.23      1267\n",
      "weighted avg       0.24      0.24      0.24      1267\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[41 51 49 32 11 28]\n",
      " [37 86 36 43  9 38]\n",
      " [36 60 56 66  9 38]\n",
      " [32 37 52 58  7 55]\n",
      " [13 31 19  9 13  7]\n",
      " [23 35 39 49  6 56]]\n"
     ]
    }
   ],
   "source": [
    "display_model_metrics(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: Same way we can try other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing Features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "hv = HashingVectorizer(dtype=np.float32,\n",
    "            strip_accents='unicode', analyzer='word',\n",
    "            ngram_range=(1, 3),n_features=2**12,non_negative=True)\n",
    "# Fitting Hash Vectorizer to both training and test sets (semi-supervised learning)\n",
    "hv.fit(list(train_df.statement.values) + list(test_df.statement.values))\n",
    "xtrain_hv =  hv.transform(train_df.statement.values) \n",
    "xvalid_hv = hv.transform(test_df.statement.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec Features\n",
    "\n",
    "Here comes the most imporant and widely used technique for text embedding. Word2vec converts word to a vector of dimension 'd'.\n",
    "\n",
    "- Word to vector of dimension 'd'\n",
    "- Can be used for both Coventation and Deep Learning modesl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>subjects</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_title</th>\n",
       "      <th>state</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true_count</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start? It started...   \n",
       "\n",
       "                             subjects         speaker         speaker_title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "\n",
       "      state party_affiliation  barely_true_count  false_counts  \\\n",
       "0     Texas        republican                0.0           1.0   \n",
       "1  Virginia          democrat                0.0           0.0   \n",
       "\n",
       "   half_true_counts  mostly_true_counts  pants_on_fire          context  \n",
       "0               0.0                 0.0            0.0         a mailer  \n",
       "1               1.0                 1.0            0.0  a floor speech.  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split(' ') for row in train['statement']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ug_sg = Word2Vec(sent, min_count=1,size= 50,workers=3, window =3, sg = 1)\n",
    "model_ug_cbow = Word2Vec(sent, min_count=1,size= 50,workers=3, window =3, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19703138, -0.061311  , -0.40880716, -0.49867463,  0.03541506,\n",
       "       -0.35453823,  0.30740044, -0.06979024, -0.3306938 ,  0.29036957,\n",
       "       -0.39855817, -0.350866  , -0.07147917,  0.3059135 ,  0.02957194,\n",
       "        0.04645884,  0.3203365 ,  1.3326272 ,  0.00597334,  0.18950194,\n",
       "       -0.16745216, -0.17665003, -0.56367654, -0.30047864, -0.3120408 ,\n",
       "       -0.23330745,  0.2790714 , -0.12381896, -0.36315352, -0.5928923 ,\n",
       "       -0.3191158 , -0.04845972,  0.44939926,  0.3536869 , -0.41129047,\n",
       "       -0.16447859, -0.10676751,  0.23111168,  0.01500688,  0.04714711,\n",
       "       -0.01127017,  0.80032605, -0.49741605,  0.22328955,  0.3381129 ,\n",
       "       -0.11633526, -0.19679421,  0.17576802,  0.29594406,  0.44566664],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_sg['Department']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10240"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_sg.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184014"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_sg.corpus_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model_ug_cbow.wv.vocab.keys():\n",
    "    embeddings_index[w] = np.append(model_ug_cbow.wv[w],model_ug_sg.wv[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['statement'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['statement', 'subjects', 'speaker', 'speaker_title', 'state',\n",
       "       'party_affiliation', 'barely_true_count', 'false_counts',\n",
       "       'half_true_counts', 'mostly_true_counts', 'pants_on_fire', 'context'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>subjects</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_title</th>\n",
       "      <th>state</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true_count</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  subjects       speaker  \\\n",
       "0  Says the Annies List political group supports ...  abortion  dwayne-bohac   \n",
       "\n",
       "          speaker_title  state party_affiliation  barely_true_count  \\\n",
       "0  State representative  Texas        republican                0.0   \n",
       "\n",
       "   false_counts  half_true_counts  mostly_true_counts  pants_on_fire   context  \n",
       "0           1.0               0.0                 0.0            0.0  a mailer  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(train.statement)\n",
    "sequences = tokenizer.texts_to_sequences(train.statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 1, 6968, 1141, 520, 621, 385, 444, 5119, 585, 11, 1601]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: each sequence is having diffirent length, lets pad it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = []\n",
    "for x in train.statement:\n",
    "    length.append(len(x.split()))\n",
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  585,   11, 1601],\n",
       "       [   0,    0,    0, ...,  560, 1365,  177],\n",
       "       [   0,    0,    0, ..., 3547,   11,  416],\n",
       "       [   0,    0,    0, ...,  467,  417, 4148],\n",
       "       [   0,    0,    0, ...,    3,  174,  505]], dtype=int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_seq = pad_sequences(sequences, maxlen=467)\n",
    "x_train_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (10240, 467)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', x_train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_val = tokenizer.texts_to_sequences(validation_raw.statement)\n",
    "x_val_seq = pad_sequences(sequences_val, maxlen=467)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 467)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 100000\n",
    "embedding_matrix = np.zeros((num_words, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(embedding_matrix[1] ,embeddings_index.get('the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(embedding_matrix[6968] ,embeddings_index.get('Annies'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.65764731, -0.02344695, -1.40152967, ...,  0.18532071,\n",
       "         0.29149911,  0.12424401],\n",
       "       [-1.08712626, -0.01805102, -1.25420547, ...,  0.291509  ,\n",
       "         0.31132948,  0.6916548 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/yekenot/2dcnn-textclassifier\n",
    "def model_cnn(embedding_matrix):\n",
    "    filter_sizes = [1,2,3,5]\n",
    "    num_filters = 36\n",
    "\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = Reshape((maxlen, embed_size, 1))(x)\n",
    "\n",
    "    maxpool_pool = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embed_size),\n",
    "                                     kernel_initializer='he_normal', activation='relu')(x)\n",
    "        maxpool_pool.append(MaxPool2D(pool_size=(maxlen - filter_sizes[i] + 1, 1))(conv))\n",
    "\n",
    "    z = Concatenate(axis=1)(maxpool_pool)   \n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(0.1)(z)\n",
    "\n",
    "    outp = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *\n",
    "import keras.backend as K\n",
    "from keras.callbacks import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO - Next steps is to try CNN, Bi-LSTM, etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
